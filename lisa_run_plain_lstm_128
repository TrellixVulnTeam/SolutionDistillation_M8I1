#!/bin/bash

#SBATCH --job-name=plain_lstm_128
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --ntasks-per-node=1
#SBATCH --time=5:00:00
#SBATCH --partition=gpu_shared
#SBATCH --gres=gpu:1

module load eb
module load Python/3.6.3-foss-2017b
module load CUDA/9.0.176
module load cuDNN/7.0.5-CUDA-9.0.176
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:/hpc/eb/Debian/cuDNN/7.0.5-CUDA-9.0.176/lib64:$LD_LIBRARY_PATH

cd /home/samigpu/Codes/SolutionDistillation

HEAD_DIR="/home/samigpu/Codes/SolutionDistillation"
CODE_DIR=$HEAD_DIR/distill
DATA_DIR=$HEAD_DIR/data
LOGS_DIR=$HEAD_DIR/logs

export PYTHONPATH=$PYTHONPATH:$HEAD_DIR

python $CODE_DIR/plain_sst_trainer.py --hidden_dim=128 \
--pretrained_embedding_path=/home/samigpu/Codes/Data/word_embeddings/glove.840B.300d/glove.840B.300d.txt \
--embedding_dim=300