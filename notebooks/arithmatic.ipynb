{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "sys.path.append(os.path.expanduser('~/Codes/SolutionDistillation'))\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from distill.common.hparams import TransformerHparam, LSTMHparam\n",
    "from distill.data_util.prep_algorithmic import AlgorithmicIdentityDecimal40, AlgorithmicAdditionDecimal40, \\\n",
    "  AlgorithmicMultiplicationDecimal40, AlgorithmicSortProblem, AlgorithmicReverseProblem, AlgorithmicIdentityBinary40\n",
    "from distill.data_util.prep_arithmatic import Arithmatic, ArithmaticSimpleSameLength10, ArithmaticSimpleSameLength10Depth2\n",
    "from distill.data_util.prep_imdb import IMDB\n",
    "from distill.data_util.prep_ptb import PTB\n",
    "from distill.data_util.prep_sst import SST\n",
    "from distill.data_util.prep_wsj_parsing import ParseWSJ\n",
    "from distill.models.lstm_seq2seq import LSTMSeq2Seq, BidiLSTMSeq2Seq\n",
    "from distill.models.transformer import Transformer, UniversalTransformer, EncodingTransformer, \\\n",
    "  EncodingUniversalTransformer\n",
    "from distill.pipelines.seq2seq import Seq2SeqTrainer\n",
    "from distill.models.transformer import Transformer, UniversalTransformer, EncodingTransformer, \\\n",
    "  EncodingUniversalTransformer\n",
    "from distill.pipelines.distill_pipelines import Seq2SeqDistiller\n",
    "from distill.pipelines.seq2seq import Seq2SeqTrainer\n",
    "\n",
    "# Enable TF Eager execution\n",
    "tfe = tf.contrib.eager\n",
    "tfe.enable_eager_execution()\n",
    "\n",
    "# Other setup\n",
    "Modes = tf.estimator.ModeKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '<eos>', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '(', ')', '+', '-']\n",
      "0 <pad>\n",
      "1 <eos>\n",
      "2 0\n",
      "3 1\n",
      "4 2\n",
      "5 3\n",
      "6 4\n",
      "7 5\n",
      "8 6\n",
      "9 7\n",
      "10 8\n",
      "11 9\n",
      "12 (\n",
      "13 )\n",
      "14 +\n",
      "15 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "task = ArithmaticSimpleSameLength10Depth2('data/arithmatic_simple_samelength10_depth2')\n",
    "\n",
    "transformer_params = TransformerHparam(input_dim=task.vocab_length,\n",
    "                                         hidden_dim=300,\n",
    "                                         output_dim=len(task.target_vocab),\n",
    "                                         encoder_depth=2,\n",
    "                                         decoder_depth=1,\n",
    "                                         number_of_heads=2,\n",
    "                                         ff_filter_size=512,\n",
    "                                         initializer_gain=0.1,\n",
    "                                         batch_size=32,\n",
    "                                         input_dropout_keep_prob=1.0,\n",
    "                                         hidden_dropout_keep_prob=1.0,\n",
    "                                         vocab_size=task.vocab_length,\n",
    "                                         label_smoothing=0.1,\n",
    "                                         encoder_self_attention_dir=\"top_down\",\n",
    "                                         decoder_self_attention_dir=\"top_down\",\n",
    "                                         decoder_cross_attention_dir=\"top_down\",\n",
    "                                         train_embeddings=False,\n",
    "                                         learning_rate=0.001\n",
    "                                         )\n",
    "trainer = Seq2SeqTrainer(transformer_params, None, task)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(\"../\"+task.get_tfrecord_path(mode=\"train\"))\n",
    "train_dataset = train_dataset.map(task.parse_examples)\n",
    "train_dataset = train_dataset.padded_batch(100, padded_shapes=task.get_padded_shapes())\n",
    "train_dataset = train_dataset.map((lambda x1,x2,x3,x4: ((x1,x2,x3,x4),(x1,x2,x3,x4))))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=100)\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "train_examples = tfe.Iterator(train_dataset).next()\n",
    "\n",
    "\n",
    "\n",
    "dev_dataset = tf.data.TFRecordDataset(\"../\"+task.get_tfrecord_path(mode=\"dev\"))\n",
    "dev_dataset = dev_dataset.map(task.parse_examples)\n",
    "dev_dataset = dev_dataset.padded_batch(100, padded_shapes=task.get_padded_shapes())\n",
    "dev_dataset = dev_dataset.shuffle(buffer_size=100)\n",
    "dev_dataset = dev_dataset.repeat()\n",
    "\n",
    "dev_examples = tfe.Iterator(dev_dataset).next()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = tf.data.TFRecordDataset(\"../\"+task.get_tfrecord_path(mode=\"test\"))\n",
    "test_dataset = test_dataset.map(task.parse_examples)\n",
    "test_dataset = test_dataset.padded_batch(100, padded_shapes=task.get_padded_shapes())\n",
    "test_dataset = test_dataset.shuffle(buffer_size=100)\n",
    "test_dataset = test_dataset.repeat()\n",
    "\n",
    "test_examples = tfe.Iterator(test_dataset).next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y= train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2169, shape=(100, 60), dtype=int64, numpy=\n",
       "array([[12,  6, 14, ...,  0,  0,  0],\n",
       "       [12,  8, 15, ...,  0,  0,  0],\n",
       "       [12, 12, 11, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [12, 11, 15, ...,  0,  0,  0],\n",
       "       [12, 12, 10, ...,  0,  0,  0],\n",
       "       [12, 12,  4, ...,  0,  0,  0]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2174, shape=(100, 1), dtype=int64, numpy=\n",
       "array([[ 3],\n",
       "       [11],\n",
       "       [10],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 5],\n",
       "       [11],\n",
       "       [ 5],\n",
       "       [ 2],\n",
       "       [ 9],\n",
       "       [ 7],\n",
       "       [11],\n",
       "       [ 6],\n",
       "       [ 9],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 9],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [11],\n",
       "       [ 5],\n",
       "       [ 4],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [ 2],\n",
       "       [ 5],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [ 3],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 4],\n",
       "       [ 5],\n",
       "       [ 2],\n",
       "       [ 8],\n",
       "       [ 7],\n",
       "       [ 9],\n",
       "       [ 7],\n",
       "       [10],\n",
       "       [ 9],\n",
       "       [ 6],\n",
       "       [ 3],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 4],\n",
       "       [ 5],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [10],\n",
       "       [11],\n",
       "       [11],\n",
       "       [10],\n",
       "       [ 6],\n",
       "       [ 2],\n",
       "       [ 9],\n",
       "       [ 7],\n",
       "       [ 6],\n",
       "       [ 3],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 2],\n",
       "       [ 6],\n",
       "       [ 4],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [ 6],\n",
       "       [ 5],\n",
       "       [ 7],\n",
       "       [ 9],\n",
       "       [ 5],\n",
       "       [10],\n",
       "       [ 9],\n",
       "       [ 5],\n",
       "       [11],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 2],\n",
       "       [ 6],\n",
       "       [11],\n",
       "       [ 7],\n",
       "       [10],\n",
       "       [ 8],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 8],\n",
       "       [ 2],\n",
       "       [11],\n",
       "       [ 3],\n",
       "       [ 7],\n",
       "       [10],\n",
       "       [ 5],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 9]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_from_examples(batched_examples):\n",
    "    lengthes = []\n",
    "    targets = []\n",
    "    for example_inputs, example_targets in zip(batched_examples[0], batched_examples[1]):\n",
    "        np_example_inputs = example_inputs.numpy()\n",
    "        np_example_targets = example_targets.numpy()[0]\n",
    "        if 0 in list(np_example_inputs):\n",
    "            length = list(np_example_inputs).index(0)\n",
    "        else:\n",
    "            length = len(np_example_inputs)\n",
    "        lengthes.append(length)\n",
    "        targets.append(np_example_targets)\n",
    "    return lengthes, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/samira/anaconda3/envs/std/lib/python3.7/site-packages (3.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/samira/anaconda3/envs/std/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/samira/anaconda3/envs/std/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/samira/anaconda3/envs/std/lib/python3.7/site-packages (from matplotlib) (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/samira/anaconda3/envs/std/lib/python3.7/site-packages (from matplotlib) (1.16.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/samira/anaconda3/envs/std/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: six in /home/samira/anaconda3/envs/std/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/samira/anaconda3/envs/std/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b8610c55fb41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlengthes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_stats_from_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengthes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b5602387a6aa>\u001b[0m in \u001b[0;36mget_stats_from_examples\u001b[0;34m(batched_examples)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mnp_example_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mnp_example_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_example_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_example_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline  \n",
    "\n",
    "\n",
    "lengthes, targets = get_stats_from_examples(train_examples)\n",
    "\n",
    "n, bins, patches = plt.hist(lengthes, 100, density=True, facecolor='g', alpha=0.75)\n",
    "plt.show()\n",
    "\n",
    "n, bins, patches = plt.hist(targets, 100, density=True, facecolor='g', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline  \n",
    "\n",
    "\n",
    "lengthes, targets = get_stats_from_examples(dev_examples)\n",
    "\n",
    "n, bins, patches = plt.hist(lengthes, 20, density=True, facecolor='g', alpha=0.75)\n",
    "plt.show()\n",
    "\n",
    "n, bins, patches = plt.hist(targets, 20, density=True, facecolor='g', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline  \n",
    "\n",
    "\n",
    "lengthes, targets = get_stats_from_examples(test_examples)\n",
    "\n",
    "n, bins, patches = plt.hist(lengthes, 20, density=True, facecolor='g', alpha=0.75)\n",
    "plt.show()\n",
    "\n",
    "n, bins, patches = plt.hist(targets, 20, density=True, facecolor='g', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '+', '1']\n"
     ]
    }
   ],
   "source": [
    "print(task.decode(task.encode(str(\"1 + 1\").split())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 100\n",
      "( 8 - 8 + 1 + ( 1 + 4 ) ) + 8 - 7 - 3 - ( 5 - ( 2 - 1 ) ) + ( 4 + 5 ) - 7 + 2 + 5 + 3 - 5 <eos>              \n",
      "7\n",
      "['7']\n",
      "( 8 - 8 + 1 + ( 1 + 4 ) ) + 8 - 7 - 3 - ( 5 - ( 2 - 1 ) ) + ( 4 + 5 ) - 7 + 2 + 5 + 3 - 5 <eos>              \n",
      "7\n",
      "tf.Tensor([9], shape=(1,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(len(train_examples[0]))\n",
    "i = 40\n",
    "print(i, len(train_examples[0][0]))\n",
    "example_inputs, example_targets = list(zip(train_examples[0][0], train_examples[0][1]))[i]\n",
    "print(' '.join(task.decode(example_inputs)).replace('<pad>',''))\n",
    "print(eval(' '.join(task.decode(example_inputs)).replace('<pad>','').replace('<eos>', '')))\n",
    "\n",
    "print(task.decode((example_targets)))\n",
    "\n",
    "\n",
    "print(' '.join(task.decode(example_inputs)).replace('<pad>',''))\n",
    "print(eval(' '.join(task.decode(example_inputs)).replace('<pad>','').replace('<eos>', '')))\n",
    "\n",
    "print(example_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits and labels must be broadcastable: logits_size=[1,10] labels_size=[1,16] [Op:SoftmaxCrossEntropyWithLogits] name: loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-65359596f353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdistiller\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeq2SeqDistiller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexample_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Codes/SolutionDistillation/distill/pipelines/seq2seq.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, logits, targets, softmax_temperature)\u001b[0m\n\u001b[1;32m     37\u001b[0m       xentropy, weights = cross_entropy_loss(\n\u001b[1;32m     38\u001b[0m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         softmax_temperature=softmax_temperature, gaussian_noise=self.task.if_label_gaussian_noise, gaussian_noise_scale=self.task.guassian_noise_scale)\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       xentropy, weights = padded_cross_entropy_loss(\n",
      "\u001b[0;32m~/Codes/SolutionDistillation/distill/common/metrics.py\u001b[0m in \u001b[0;36mcross_entropy_loss\u001b[0;34m(logits, labels, smoothing, vocab_size, softmax_temperature, gaussian_noise, gaussian_noise_scale)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(\n\u001b[0;32m---> 74\u001b[0;31m           logits=logits, labels=soft_targets)\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0;31m# Calculate the best (lowest) possible value of cross entropy, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/std/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/envs/std/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy_with_logits_v2_helper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2469\u001b[0m     \u001b[0;31m# _CrossEntropyGrad() in nn_grad but not here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m     cost, unused_backprop = gen_nn_ops.softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 2471\u001b[0;31m         precise_logits, labels, name=name)\n\u001b[0m\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2473\u001b[0m     \u001b[0;31m# The output cost shape should be the input minus axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/std/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy_with_logits\u001b[0;34m(features, labels, name)\u001b[0m\n\u001b[1;32m   7856\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7857\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7858\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7859\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7860\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n",
      "\u001b[0;32m~/anaconda3/envs/std/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[1,10] labels_size=[1,16] [Op:SoftmaxCrossEntropyWithLogits] name: loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/"
     ]
    }
   ],
   "source": [
    "model_1 = EncodingTransformer(transformer_params, task, \"model_1\")\n",
    "model_2 = EncodingTransformer(transformer_params, task, \"model_2\")\n",
    "\n",
    "trainer = Seq2SeqTrainer(transformer_params, model_1, task)\n",
    "distiller = Seq2SeqDistiller(transformer_params, model_1, model_2, trainer)\n",
    "    \n",
    "trainer.compute_loss(tf.one_hot(example_targets,10),example_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3622, shape=(1,), dtype=int64, numpy=array([9])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5344, shape=(1, 16), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(example_targets,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distill.common.metrics import padded_cross_entropy_loss, get_eval_metrics, cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy, weights = cross_entropy_loss(tf.one_hot(example_targets,10),example_targets,smoothing=0.0,vocab_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5410, shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5406, shape=(1,), dtype=float32, numpy=array([1.4611502], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_targets = tf.one_hot(\n",
    "            tf.cast(example_targets, tf.int32),\n",
    "            depth=10,\n",
    "            on_value=1.0,\n",
    "            off_value=0.0)\n",
    "              \n",
    "      \n",
    "      \n",
    "xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "  logits=soft_targets*100, labels=soft_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5453, shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5419, shape=(1, 10), dtype=float32, numpy=array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5459, shape=(1, 10), dtype=float32, numpy=array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(example_targets,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-2609ab84cd53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.create_vars()\n",
    "outputs = model.apply(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1000), Dimension(1), Dimension(10)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=40896, shape=(1000, 1, 10), dtype=float32, numpy=\n",
       "array([[[0.00715524, 0.09209497, 0.0917704 , ..., 0.03556783,\n",
       "         0.04943119, 0.15343009]],\n",
       "\n",
       "       [[0.02895103, 0.04006007, 0.26865193, ..., 0.00580688,\n",
       "         0.07627358, 0.02107685]],\n",
       "\n",
       "       [[0.04077142, 0.02672941, 0.23326753, ..., 0.00361042,\n",
       "         0.04985133, 0.04474999]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.01969549, 0.02658502, 0.2711329 , ..., 0.00517109,\n",
       "         0.05861397, 0.04302977]],\n",
       "\n",
       "       [[0.02205601, 0.05488703, 0.26217592, ..., 0.00449226,\n",
       "         0.06337234, 0.0239463 ]],\n",
       "\n",
       "       [[0.04000373, 0.05206897, 0.24202158, ..., 0.01508354,\n",
       "         0.07866572, 0.02239132]]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['trainable_vars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transformer'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/samira/Codes/SolutionDistillation/distill/models/transformer.py:588: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n",
      "[<tf.Variable 'model_1/TransformerEncoder/layer_norm_scale:0' shape=(300,) dtype=float32_ref>, <tf.Variable 'model_1/TransformerEncoder/layer_norm_bias:0' shape=(300,) dtype=float32_ref>]\n",
      "[<tf.Variable 'model_2/TransformerEncoder/layer_norm_scale:0' shape=(300,) dtype=float32_ref>, <tf.Variable 'model_2/TransformerEncoder/layer_norm_bias:0' shape=(300,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    model_1.create_vars(False)\n",
    "    model_2.create_vars(False)\n",
    "    print(tf.trainable_variables(\"model_1\"))\n",
    "    print(tf.trainable_variables(\"model_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "model = EncodingTransformer(transformer_params, task)\n",
    "model.create_vars(False)\n",
    "print(tf.trainable_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'model_2/TransformerEncoder/layer_norm_scale:0' shape=(300,) dtype=float32_ref>, <tf.Variable 'model_2/TransformerEncoder/layer_norm_bias:0' shape=(300,) dtype=float32_ref>]\n",
      "[<tf.Variable 'model_1/TransformerEncoder/layer_norm_scale:0' shape=(300,) dtype=float32_ref>, <tf.Variable 'model_1/TransformerEncoder/layer_norm_bias:0' shape=(300,) dtype=float32_ref>, <tf.Variable 'model_2/TransformerEncoder/layer_norm_scale:0' shape=(300,) dtype=float32_ref>, <tf.Variable 'model_2/TransformerEncoder/layer_norm_bias:0' shape=(300,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    model_1.create_vars(False)\n",
    "    model_2.create_vars(False)\n",
    "    model_1_vars = tf.trainable_variables(\"model_1\")\n",
    "    model_2_vars = tf.trainable_variables(\"model_2\")\n",
    "    print(model_2_vars)\n",
    "    print(model_1_vars + model_2_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
