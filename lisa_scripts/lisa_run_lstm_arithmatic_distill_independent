#!/bin/bash

#SBATCH --job-name=distill
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --ntasks-per-node=1
#SBATCH --time=24:00:00
#SBATCH --partition=gpu

module load eb
module load Python/3.6.3-foss-2017b
module load CUDA/10.0.130
module load cuDNN/7.3.1-CUDA-10.0.130
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:/hpc/eb/Debian/cuDNN/7.3.1-CUDA-10.0.130/lib64:$LD_LIBRARY_PATH

#cd /home/samigpu/Codes/SolutionDistillation

HEAD_DIR="/home/samigpu/Codes/SolutionDistillation"
CODE_DIR=$HEAD_DIR/distill
DATA_DIR=$HEAD_DIR/data
LOGS_DIR=$HEAD_DIR/logs

#mkdir "$TMPDIR"/samigpu
#TMP_DATA_DIR="$TMPDIR"/samigpu/data
TMP_LOGS_DIR="$TMPDIR"/samigpu/logs

#mkdir $TMP_DATA_DIR
#mkdir $TMP_LOGS_DIR

#Copy input file to scratch
#cp -r "$DATA_DIR"/* "$TMP_DATA_DIR"/
#cp -r "$LOGS_DIR"/* "$TMP_LOGS_DIR"/

echo "$TMP_LOGS_DIR"
export PYTHONPATH=$PYTHONPATH:$HEAD_DIR

CUDA_VISIBLE_DEVICES=0 python $CODE_DIR/seq2seq_distiller.py \
--log_dir="$TMP_LOGS_DIR" --data_dir="$TMP_DATA_DIR" \
--batch_size=64 --teacher_hidden_dim=128 --student_hidden_dim=128 \
--teacher_model=lstm --student_model=lstm \
--teacher_train_embeddings=True --student_train_embeddings=True \
--student_decoder_depth=1 --student_encoder_depth=1 --teacher_decoder_depth=1 --teacher_encoder_depth=2 \
--student_input_dropout_keep_prob=1.0 --student_hidden_dropout_keep_prob=1.0 \
--teacher_input_dropout_keep_prob=1.0 --teacher_hidden_dropout_keep_prob=1.0 \
--student_learning_rate=0.001 \
--teacher_learning_rate=0.001 \
--distill_learning_rate=0.001 \
--data_weight=1.0 \
--distill_logits_weight=0.0 \
--decay_learning_rate=True --l2_rate=0.00 \
--student_encoder_attention_dir="top_down" \
--teacher_encoder_attention_dir="top_down" \
--train_student=True --train_teacher=True \
--distill_rep=False distill_logit=False \
--distill_temp=1.0 \
--task_name=arithmatic_simple_samelength10_depth2 --exp_name=_indp_bothnoreg &

CUDA_VISIBLE_DEVICES=1 python $CODE_DIR/seq2seq_distiller.py \
--log_dir="$TMP_LOGS_DIR" --data_dir="$TMP_DATA_DIR" \
--batch_size=64 --teacher_hidden_dim=128 --student_hidden_dim=128 \
--teacher_model=lstm --student_model=lstm \
--teacher_train_embeddings=True --student_train_embeddings=True \
--student_decoder_depth=1 --student_encoder_depth=1 --teacher_decoder_depth=1 --teacher_encoder_depth=2 \
--student_input_dropout_keep_prob=0.8 --student_hidden_dropout_keep_prob=0.9 \
--teacher_input_dropout_keep_prob=0.8 --teacher_hidden_dropout_keep_prob=0.9 \
--student_learning_rate=0.001 \
--teacher_learning_rate=0.001 \
--distill_learning_rate=0.001 \
--data_weight=1.0 \
--distill_logits_weight=0.0 \
--decay_learning_rate=True --l2_rate=0.0001 \
--student_encoder_attention_dir="top_down" \
--teacher_encoder_attention_dir="top_down" \
--train_student=True --train_teacher=True \
--distill_rep=False distill_logit=False \
--distill_temp=1.0 \
--task_name=arithmatic_simple_samelength10_depth2 --exp_name=_indp_bothreg &

CUDA_VISIBLE_DEVICES=2 python $CODE_DIR/seq2seq_distiller.py \
--log_dir="$TMP_LOGS_DIR" --data_dir="$TMP_DATA_DIR" \
--batch_size=64 --teacher_hidden_dim=128 --student_hidden_dim=128 \
--teacher_model=lstm --student_model=lstm \
--teacher_train_embeddings=True --student_train_embeddings=True \
--student_decoder_depth=1 --student_encoder_depth=1 --teacher_decoder_depth=1 --teacher_encoder_depth=2 \
--student_input_dropout_keep_prob=0.8 --student_hidden_dropout_keep_prob=0.9 \
--teacher_input_dropout_keep_prob=0.8 --teacher_hidden_dropout_keep_prob=0.9 \
--student_learning_rate=0.001 \
--teacher_learning_rate=0.001 \
--distill_learning_rate=0.001 \
--data_weight=1.0 \
--distill_logits_weight=0.0 \
--decay_learning_rate=True --l2_rate=0.0001 \
--student_encoder_attention_dir="top_down" \
--teacher_encoder_attention_dir="top_down" \
--train_student=True --train_teacher=True \
--distill_rep=False distill_logit=False \
--distill_temp=1.0 \
--task_name=arithmatic_simple_samelength10_depth4 --exp_name=_indp_bothreg &

CUDA_VISIBLE_DEVICES=3 python $CODE_DIR/seq2seq_distiller.py \
--log_dir="$TMPLOGS_DIR" --data_dir="$TMP_DATA_DIR" \
--batch_size=64 --teacher_hidden_dim=128 --student_hidden_dim=128 \
--teacher_model=lstm --student_model=lstm \
--teacher_train_embeddings=True --student_train_embeddings=True \
--student_decoder_depth=1 --student_encoder_depth=1 --teacher_decoder_depth=1 --teacher_encoder_depth=2 \
--student_input_dropout_keep_prob=0.8 --student_hidden_dropout_keep_prob=0.9 \
--teacher_input_dropout_keep_prob=0.8 --teacher_hidden_dropout_keep_prob=0.9 \
--student_learning_rate=0.001 \
--teacher_learning_rate=0.001 \
--distill_learning_rate=0.001 \
--data_weight=1.0 \
--distill_logits_weight=0.0 \
--decay_learning_rate=True --l2_rate=0.0001 \
--student_encoder_attention_dir="top_down" \
--teacher_encoder_attention_dir="top_down" \
--train_student=True --train_teacher=True \
--distill_rep=False distill_logit=False \
--distill_temp=1.0 \
--task_name=arithmatic_simple_samelength10_depth6 --exp_name=_indp_bothreg &

wait

#Copy input file to scratch
cp -r  "$TMP_DATA_DIR"/* "$DATA_DIR"/
cp -r  "$TMP_LOGS_DIR"/* "$LOGS_DIR"/

